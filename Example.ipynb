{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An experimental notebook for testing the CFBCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.argv = ['run.py']\n",
    "from utils.options import process_args\n",
    "from dataset.dataset_survival_tcga import Generic_MIL_Survival_Dataset\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = process_args()\n",
    "\n",
    "# Dataset organization\n",
    "ORGANIZE=\"TCGA\" # TCGA; CPTAC\n",
    "# Dataset root dir\n",
    "BASE_DIR=f\"/mnt/jzy8T/jzy/{ORGANIZE}\"\n",
    "# Dataset: BLCA; BRCA; LUAD; UCEC; GBMLGG; COAD; HNSC; STAD; \n",
    "DATASET=\"STAD\"  \n",
    "# Omic-modal: snn; mlp; mmlp\n",
    "# Path-modal: deepset; amil; tmil; amisl; clam-sb; clam-mb; mqp\n",
    "# Muti-modal: mcat; cmta; cfbct; mbct; motcat; porpoise; survpath; ponet; mgct\n",
    "args.model_type='cfbct' \n",
    "# Modality: omic; path; cluster; coattn\n",
    "args.mode='coattn'\n",
    "# Omega_k: 0.4,0.6,0.8,1.0\n",
    "args.W_k=1.0 \n",
    "# Use tensorboard ? default: False\n",
    "args.log_data=False\n",
    "# Use function groups or pathway groups? default: True\n",
    "args.apply_sig=True\n",
    "# Save model? default: False \n",
    "args.save_pkl=False\n",
    "# Save model checkpoints? default: False \n",
    "args.save_ckp=False\n",
    "# \n",
    "args.data_root_dir=f\"{BASE_DIR}/{DATASET}\"\n",
    "args.split_dir=f\"{ORGANIZE.lower()}_{DATASET.lower()}\"\n",
    "args.n_classes = 4\n",
    "args.dataset_path='dataset_csv'\n",
    "\n",
    "# select fold\n",
    "fold= 0\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_torch(args.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) : 0\n",
      "(0, 1) : 1\n",
      "(1, 0) : 2\n",
      "(1, 1) : 3\n",
      "(2, 0) : 4\n",
      "(2, 1) : 5\n",
      "(3, 0) : 6\n",
      "(3, 1) : 7\n",
      "label column: survival_months\n",
      "label dictionary: {(0, 0): 0, (0, 1): 1, (1, 0): 2, (1, 1): 3, (2, 0): 4, (2, 1): 5, (3, 0): 6, (3, 1): 7}\n",
      "number of classes: 8\n",
      "slide-level counts:  \n",
      " 7    112\n",
      "5     48\n",
      "4     30\n",
      "6     30\n",
      "2     30\n",
      "3     11\n",
      "0     30\n",
      "1     27\n",
      "Name: label, dtype: int64\n",
      "Patient-LVL; Number of samples registered in class 0: 30\n",
      "Slide-LVL; Number of samples registered in class 0: 30\n",
      "Patient-LVL; Number of samples registered in class 1: 27\n",
      "Slide-LVL; Number of samples registered in class 1: 27\n",
      "Patient-LVL; Number of samples registered in class 2: 30\n",
      "Slide-LVL; Number of samples registered in class 2: 30\n",
      "Patient-LVL; Number of samples registered in class 3: 11\n",
      "Slide-LVL; Number of samples registered in class 3: 11\n",
      "Patient-LVL; Number of samples registered in class 4: 30\n",
      "Slide-LVL; Number of samples registered in class 4: 30\n",
      "Patient-LVL; Number of samples registered in class 5: 48\n",
      "Slide-LVL; Number of samples registered in class 5: 48\n",
      "Patient-LVL; Number of samples registered in class 6: 30\n",
      "Slide-LVL; Number of samples registered in class 6: 30\n",
      "Patient-LVL; Number of samples registered in class 7: 112\n",
      "Slide-LVL; Number of samples registered in class 7: 112\n",
      "****** Normalizing Data ******\n"
     ]
    }
   ],
   "source": [
    "csv_path = './%s/%s_all_clean.csv.zip' % (args.dataset_path, args.split_dir)\n",
    "# loading dataset \n",
    "dataset = Generic_MIL_Survival_Dataset(csv_path=csv_path,\n",
    "                                        mode=args.mode,\n",
    "                                        apply_sig=args.apply_sig,\n",
    "                                        data_dir=args.data_root_dir,\n",
    "                                        shuffle=False,\n",
    "                                        seed=args.seed,\n",
    "                                        print_info=True,\n",
    "                                        patient_strat=False,\n",
    "                                        n_bins=4,\n",
    "                                        label_col='survival_months',\n",
    "                                        ignore=[])\n",
    "\n",
    "from utils.generate_utils import *\n",
    "from utils.utils import get_split_loader\n",
    "\n",
    "# split dataset \n",
    "split_dir = os.path.join('./splits', '5foldcv', args.split_dir)\n",
    "train_dataset, val_dataset =dataset.return_splits(from_id=False,csv_path='{}/splits_{}.csv'.format(split_dir, fold))\n",
    "# generate omic_sizes \n",
    "args.omic_sizes = train_dataset.omic_sizes\n",
    "# generate loader \n",
    "train_loader = get_split_loader(train_dataset, testing = False, mode=args.mode, batch_size=args.batch_size)\n",
    "val_loader = get_split_loader(val_dataset,  testing = False, mode=args.mode, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the downloaded model checkpoint\n",
    "ckp_base='<checkpoint path>'\n",
    "args.path_load_model=os.path.join(ckp_base,f's_{fold}_checkpoint.pt')\n",
    "# The weights of the three branches when the optimal performance is preserved\n",
    "cfc=[0.1,0.1,0.1] \n",
    "# \n",
    "model=generate_model(args=args).to(device)\n",
    "\n",
    "if device.type=='cpu':\n",
    "    checkpoint= torch.load(args.path_load_model,map_location=lambda storage, loc: storage)\n",
    "else:\n",
    "    checkpoint= torch.load(args.path_load_model)\n",
    "\n",
    "model.load_state_dict(checkpoint,strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Runing Experiment on Val Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "patient_results = {}\n",
    "\n",
    "slide_ids = val_loader.dataset.slide_data['slide_id']\n",
    "loader_len=len(slide_ids)\n",
    "\n",
    "all_risk_scores = np.zeros((len(val_loader)))\n",
    "all_censorships = np.zeros((len(val_loader)))\n",
    "all_event_times = np.zeros((len(val_loader)))\n",
    "\n",
    "for batch_idx, (data_WSI, data_omic, label, event_time, c) in enumerate(val_loader):\n",
    "\n",
    "        data_WSI = data_WSI.cuda()\n",
    "        data_omic1 = data_omic[0][0].type(torch.FloatTensor).to(device)\n",
    "        data_omic2 = data_omic[0][1].type(torch.FloatTensor).to(device)\n",
    "        data_omic3 = data_omic[0][2].type(torch.FloatTensor).to(device)\n",
    "        data_omic4 = data_omic[0][3].type(torch.FloatTensor).to(device)\n",
    "        data_omic5 = data_omic[0][4].type(torch.FloatTensor).to(device)\n",
    "        data_omic6 = data_omic[0][5].type(torch.FloatTensor).to(device)\n",
    "        label = label.type(torch.LongTensor).cuda()\n",
    "        c = c.type(torch.FloatTensor).cuda()\n",
    "\n",
    "        slide_id = slide_ids.iloc[batch_idx]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(cfc=cfc,x_path=data_WSI, x_omic1=data_omic1, x_omic2=data_omic2, x_omic3=data_omic3, x_omic4=data_omic4, x_omic5=data_omic5, x_omic6=data_omic6)\n",
    "        risk = -torch.sum(output['S'], dim=1).cpu().numpy()\n",
    "        patient_results.update({\n",
    "            slide_id: {'slide_id': np.array(slide_id), \n",
    "                    'risk': risk, \n",
    "                    'disc_label': label.item(), \n",
    "                    'survival': event_time.item(), \n",
    "                    'censorship': c.item()}})\n",
    "        slide_ids = val_loader.dataset.slide_data['slide_id']\n",
    "      \n",
    "        risk = -torch.sum(output['cf_S'], dim=1).cpu().numpy()\n",
    "\n",
    "        all_risk_scores[batch_idx] = risk\n",
    "        all_censorships[batch_idx] = c.cpu().numpy()\n",
    "        all_event_times[batch_idx] = event_time\n",
    "        patient_results.update({slide_id: {'slide_id': np.array(slide_id), 'risk': risk, 'disc_label': label.item(), 'survival': event_time.item(), 'censorship': c.item()}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cindex Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val c-index: 0.7372\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "c_index = concordance_index_censored((1-all_censorships).astype(bool), all_event_times, all_risk_scores, tied_tol=1e-08)[0]\n",
    "print(\"val c-index: {:.4f}\".format(c_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
